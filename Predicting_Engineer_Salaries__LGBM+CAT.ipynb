{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predicting_Engineer_Salaries__LGBM+CAT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pea-sys/Quevico/blob/master/Predicting_Engineer_Salaries__LGBM%2BCAT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN-B7OY0A2QP",
        "colab_type": "text"
      },
      "source": [
        "#StackOverFlowのアンケート内容から回答者の給与を予測@Quevico\n",
        "順位：2位/256人(暫定)  \n",
        "環境：所有PCがタブレットしかないため、GoogleColabで実装しています。  \n",
        "モデル：重要な特徴量を足し引きしたLGBMモデル3個とCatboostモデル3個のアンサンブル  \n",
        "工夫した点：\n",
        "\n",
        "\n",
        "*   未解答欄の多いユーザのweightを下げる\n",
        "*   フルトレイン\n",
        "*   年収に寄与しない特徴の加工(未就業者のスキルセットをnanで埋める等)  \n",
        "*   交互作用項の作りこみ\n",
        "\n",
        "感想：  \n",
        "３万円とはいえ、初めて賞金圏を取ったコンペになった。  \n",
        "今回初めてCatBoostを使用したが、カテゴリ値が多くデータがやや少ないものに適していると感じた。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmHJchuQvuiE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "0ade12af-4d71-4d61-9032-607a1712e3ff"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Sep  5 21:00:09 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    25W / 300W |      0MiB / 16130MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzjqCKGxFIp0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "375051f2-4bb0-450d-fc3c-ffcd372d4424"
      },
      "source": [
        "!pip install category_encoders\n",
        "!pip install -U catboost"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.6/dist-packages (2.2.2)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.0.5)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.22.2.post1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.16.0)\n",
            "Requirement already up-to-date: catboost in /usr/local/lib/python3.6/dist-packages (0.24.1)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-bf855yFUzY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6a06733-18ac-4d2c-bb92-aae2a3ad0e7e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbONU8VoFere",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e16ad53a-d3db-4f3e-ae88-ddffa513c584"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/quevico"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/quevico\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3_yyx74Frn1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, sys, gc, time, warnings, random, pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import accuracy_score\n",
        "from math import sqrt\n",
        "import lightgbm as lgb\n",
        "import catboost as cat\n",
        "from catboost import CatBoostRegressor, Pool, cv\n",
        "import category_encoders as ce"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrZCowqiGLTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.max_rows', 129)\n",
        "pd.set_option(\"display.max_colwidth\", 500)\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYxAeG8KGmuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SUB_FILE = \"submit.csv\"\n",
        "TEST_FILE = \"test.csv\"\n",
        "TRAIN_FILE= \"train.csv\"\n",
        "QUESTION_FILE = \"question.csv\"\n",
        "TARGET = \"Salary\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaCZYWptGo3o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a42216c2-747d-4f8b-b542-76978dec35d5"
      },
      "source": [
        "train_data = pd.read_csv(TRAIN_FILE)\n",
        "train_data = train_data.set_index('No')\n",
        "test_data = pd.read_csv(TEST_FILE)\n",
        "test_data[TARGET] = 0\n",
        "test_data = test_data.set_index('No')\n",
        "print(train_data.shape,test_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(33857, 127) (11259, 127)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQPldOT4HBiS",
        "colab_type": "text"
      },
      "source": [
        "#Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYyrMdaEIyWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_nan_count_and_clean(df):\n",
        "  print('add_nan_count start',df.shape)\n",
        "  df['nanCnt'] = df.isnull().sum(axis=1)\n",
        "  df['nanCnt'] = df['nanCnt'].astype(np.int16)\n",
        "  \n",
        "  df['HypotheticalTools_Total'] = 0\n",
        "  c = 'HypotheticalTools'\n",
        "  for i in range(1,6):\n",
        "    df[c+str(i)] = df[c+str(i)].astype(np.object)\t\n",
        "    df.loc[df[c+str(i)]=='Not at all interested','HypotheticalTools_Total'] +=  np.sqrt(1)\n",
        "    df.loc[df[c+str(i)]=='Somewhat interested','HypotheticalTools_Total'] += np.sqrt(3)\n",
        "    df.loc[df[c+str(i)]=='A little bit interested','HypotheticalTools_Total'] += np.sqrt(4)\n",
        "    df.loc[df[c+str(i)]=='Very interested','HypotheticalTools_Total'] += np.sqrt(5)\n",
        "    df.loc[df[c+str(i)]=='Extremely interested','HypotheticalTools_Total'] += np.sqrt(6)\n",
        "    del df[c+str(i)]\n",
        "  df['HypotheticalTools_Total'] = df['HypotheticalTools_Total'].astype(np.int8)\n",
        "  #趣味でプログラミングやっていない場合\n",
        "  df.loc[df['Hobby']== 'No','HoursComputer'] = 'Less than 1 hour'\n",
        "  df.loc[(df['LastNewJob']==r\"I've never had a job\") & (df['DevType'].astype(str).str.contains(\"Student\")),'DevType'] = \"Student\"\n",
        "  df.loc[df['LastNewJob']==r\"I've never had a job\",'CommunicationTools'] = np.nan\n",
        "  df.loc[df['LastNewJob']==r\"I've never had a job\",'LanguageWorkedWith'] = np.nan\n",
        "  df.loc[df['LastNewJob']==r\"I've never had a job\",'LanguageDesireNextYear'] = np.nan\n",
        "  df.loc[df['LastNewJob']==r\"I've never had a job\",'Methodology'] = np.nan\n",
        "  df.loc[df['LastNewJob']==r\"I've never had a job\",'FrameworkDesireNextYear'] = np.nan\n",
        "  df.loc[df['LastNewJob']==r\"I've never had a job\",'FrameworkWorkedWith'] = np.nan\n",
        "  df.loc[df['LastNewJob']==r\"I've never had a job\",'PlatformDesireNextYear'] = np.nan\n",
        "  df.loc[df['LastNewJob']==r\"I've never had a job\",'PlatformWorkedWith'] = np.nan\n",
        "  df.loc[df['LastNewJob']==r\"I've never had a job\",'DatabaseDesireNextYear'] = np.nan\n",
        "  df.loc[df['LastNewJob']==r\"I've never had a job\",'DatabaseWorkedWith'] = np.nan\n",
        "  df.loc[df['LastNewJob']==r\"I've never had a job\",'HackathonReasons'] = np.nan\n",
        "  df.loc[df['LastNewJob']==r\"I've never had a job\",'SelfTaughtTypes'] = np.nan\n",
        "  df.loc[df['LastNewJob']==r\"I've never had a job\",'EducationTypes'] = np.nan\n",
        "  df.loc[df['LastNewJob']==r\"I've never had a job\",'IDE'] = np.nan\n",
        "  df.loc[df['LastNewJob']==r\"I've never had a job\",'VersionControl'] = np.nan\n",
        "  df.loc[(df['LastNewJob']==r\"I've never had a job\") & (df['Country']=='United States'),'MilitaryUS'] = 'No'\n",
        "  df.loc[df['LastNewJob']==r\"I've never had a job\",'CompanySize'] = np.nan\n",
        "  df.loc[df['LastNewJob']==r\"I've never had a job\",'YearsCodingProf'] = np.nan\n",
        "  df.loc[df['LastNewJob']==r\"I've never had a job\",'Employment'] = 'Not employed, and not looking for work'\n",
        "  #TRAINのみ(暫定)\n",
        "  if test_data[TARGET].sum() != 0:\n",
        "    print(\"train\")\n",
        "    df = df.loc[~((df['LastNewJob']==r\"I've never had a job\") & (df['Age'] == '35 - 44 years old'))]\n",
        "    df.loc[(df['LastNewJob']==r\"I've never had a job\") & (df[TARGET]>=50000) ,'LastNewJob'] = np.nan\n",
        "  print('add_nan_count end',df.shape)\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AE5DcJJKH_68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_feature_split(df):\n",
        "  print('preprocess_feature_split start',df.shape)\n",
        "  split_features = ['DevType','CommunicationTools','HackathonReasons','LanguageWorkedWith','DatabaseWorkedWith','PlatformWorkedWith','VersionControl','RaceEthnicity']\n",
        "  split_features += ['EducationTypes','SelfTaughtTypes','FrameworkWorkedWith','FrameworkDesireNextYear','IDE','Methodology','AdsActions','ErgonomicDevices']\n",
        "  split_features += ['SexualOrientation','LanguageDesireNextYear','PlatformDesireNextYear','DatabaseDesireNextYear']\n",
        "  split_features += ['AdBlockerReasons','Gender']\n",
        "\n",
        "  for s in split_features:\n",
        "    df[s] = df[s].str.replace('Visual Studio Code','VSCode',regex = True)\n",
        "    df[s] = df[s].str.replace(r'(','',regex = True) #括弧で囲まれていると変換できない\n",
        "    df[s] = df[s].str.replace(r')','',regex = True)\n",
        "    df[s] = df[s].str.replace(r'+','p',regex = True)\n",
        "    df[s] = df[s].str.replace(r'+','p',regex = True)\n",
        "    df[s] = df[s].str.replace(r'[','p',regex = True)\n",
        "    df[s] = df[s].str.replace(r']','p',regex = True)\n",
        "    df[s] = df[s].str.replace(r'{','p',regex = True)\n",
        "    df[s] = df[s].str.replace(r'}','p',regex = True)\n",
        "    df[s] = df[s].str.replace(r\",\",'p',regex = True)\n",
        "\n",
        "    df[s+'Count'] = df[s].astype(str).apply(lambda x: len(x.split(\";\")))\n",
        "    df[s+'Count'] = df[s+'Count'].astype(np.int8)\n",
        "    df[s].fillna('Nothing',inplace=True)\n",
        "    l = list()\n",
        "    for r in df[s].str.split(';').values:\n",
        "      l.extend(r) \n",
        "    l = list(set(l))\n",
        "\n",
        "    for o in l:\n",
        "      df[s + \"_\" + o] = df[r\"\"+ s].str.contains(r\"\" + o)\n",
        "    del df[s]\n",
        "    del df[s+\"_Nothing\"]\n",
        "  print('preprocess_feature_split end',df.shape)\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQZGyChwxPlh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_other(df):\n",
        "  print('preprocess start',df.shape)\n",
        "  #プロ経験がないため、倫理観に信頼性なし\n",
        "  for c in ['EthicsChoice','EthicsReport','EthicsResponsible','EthicalImplications']:\n",
        "    df.loc[df['YearsCodingProf'].isnull(),c] = np.nan\n",
        "\n",
        "  #コーディング経験の矛盾修正\n",
        "  df.loc[df['YearsCoding'] < df['YearsCodingProf'],'YearsCodingProf'] = df['YearsCoding']\n",
        "\n",
        "  #NaN補完\n",
        "  df.loc[df['YearsCoding'].isnull(),'YearsCoding'] = df['YearsCodingProf']\n",
        "  df = df.loc[~df['JobSearchStatus'].isnull()]\n",
        "\n",
        "  df.loc[(df['SelfTaughtTypes_A book or e-book from O’Reillyp Apressp or a similar publisher']) & (df['Age']<=24),'SelfTaughtTypes_A book or e-book from O’Reillyp Apressp or a similar publisher'] = False\n",
        "  df.loc[(df['EducationTypes_Participated in online coding competitions e.g. HackerRankp CodeChefp TopCoder']) & (df['Age']>=44),'EducationTypes_Participated in online coding competitions e.g. HackerRankp CodeChefp TopCoder'] = False\n",
        "  df.loc[(df['EducationTypes_Completed an industry certification program e.g. MCPD']) & (df['Age']<=24),'EducationTypes_Completed an industry certification program e.g. MCPD'] = False\n",
        "  print('preprocess end',df.shape)\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RL8s3saasyJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_encoder(df):\n",
        "  print(\"feature_encoder start\")\n",
        "  for c in ['YearsCoding','YearsCodingProf']:\n",
        "    df.loc[df[c]=='0-2 years',c] = 1\n",
        "    df.loc[df[c]=='3-5 years',c] = 4\n",
        "    df.loc[df[c]=='6-8 years',c] = 7\n",
        "    df.loc[df[c]=='9-11 years',c] = 10\n",
        "    df.loc[df[c]=='12-14 years',c] = 13\n",
        "    df.loc[df[c]=='15-17 years',c] = 16\n",
        "    df.loc[df[c]=='18-20 years',c] = 19\n",
        "    df.loc[df[c]=='21-23 years',c] = 22\n",
        "    df.loc[df[c]=='24-26 years',c] = 25\n",
        "    df.loc[df[c]=='27-29 years',c] = 28\n",
        "    df.loc[df[c]=='30 or more years',c] = 31\n",
        "    df[c] = df[c].astype(np.float32)\n",
        "\n",
        "  c = 'Age'\n",
        "  df.loc[df[c]=='Under 18 years old',c] = 18\n",
        "  df.loc[df[c]=='18 - 24 years old',c] = 24\n",
        "  df.loc[df[c]=='25 - 34 years old',c] = 34\n",
        "  df.loc[df[c]=='35 - 44 years old',c] = 44\n",
        "  df.loc[df[c]=='45 - 54 years old',c] = 54\n",
        "  df.loc[df[c]=='55 - 64 years old',c] = 64\n",
        "  df.loc[df[c]=='65 years or older',c] = 74\n",
        "  df[c] = df[c].astype(np.float32)\n",
        "  \n",
        "  c = 'Student'\n",
        "  df.loc[df[c]=='Yes, full-time',c] = 8\n",
        "  df.loc[df[c]=='Yes, part-time',c] = 4\n",
        "  df.loc[df[c]=='No',c] = 0\n",
        "  df[c] = df[c].astype(np.float16)\n",
        "\n",
        "  c = 'CompanySize'\n",
        "  df.loc[df[c]=='Fewer than 10 employees',c] = np.sqrt(9) \n",
        "  df.loc[df[c]=='10 to 19 employees',c] = np.sqrt(19)\n",
        "  df.loc[df[c]=='20 to 99 employees',c] = np.sqrt(99)\n",
        "  df.loc[df[c]=='100 to 499 employees',c] = np.sqrt(499)\n",
        "  df.loc[df[c]=='500 to 999 employees',c] = np.sqrt(999)\n",
        "  df.loc[df[c]=='1,000 to 4,999 employees',c] = np.sqrt(4999)\n",
        "  df.loc[df[c]=='5,000 to 9,999 employees',c] = np.sqrt(9999)\n",
        "  df.loc[df[c]=='10,000 or more employees',c] = np.sqrt(10000)\n",
        "  df[c] = df[c].astype(np.float32)\n",
        "\n",
        "  c = 'Employment'\n",
        "  df.loc[df[c]=='Employed full-time',c] = 8\n",
        "  df.loc[df[c]=='Independent contractor, freelancer, or self-employed',c] = 8\n",
        "  df.loc[df[c]=='Employed part-time',c] = 4\n",
        "  df.loc[df[c]=='Not employed, but looking for work',c] = 0\n",
        "  df.loc[df[c]=='Not employed, and not looking for work',c] = 0\n",
        "  df.loc[df[c]=='Retired',c] = 0\n",
        "  df[c] = df[c].astype(np.float16)\n",
        "\n",
        "  c = 'HoursOutside'\n",
        "  df.loc[df[c]=='Less than 30 minutes',c] = 30 \n",
        "  df.loc[df[c]=='30 - 59 minutes',c] = 59 \n",
        "  df.loc[df[c]=='1 - 2 hours',c] = 120\n",
        "  df.loc[df[c]=='3 - 4 hours',c] = 240\n",
        "  df.loc[df[c]=='Over 4 hours',c] = 300\n",
        "  df[c].fillna(-999,inplace=True)\n",
        "  df[c] = df[c].astype(np.int16)\n",
        "\n",
        "  c = 'HoursComputer'\n",
        "  df.loc[df[c]=='Less than 1 hour',c] =  np.sqrt(1)\n",
        "  df.loc[df[c]=='1 - 4 hours',c] =  np.sqrt(4)\n",
        "  df.loc[df[c]=='5 - 8 hours',c] =  np.sqrt(8)\n",
        "  df.loc[df[c]=='9 - 12 hours',c] =  np.sqrt(12)\n",
        "  df.loc[df[c]=='Over 12 hours',c] =  np.sqrt(16)\n",
        "  df[c] = df[c].astype(np.float16)\n",
        "\n",
        "  c = 'SkipMeals'\n",
        "  df.loc[df[c]=='Never',c] = 0\n",
        "  df.loc[df[c]=='Daily or almost every day',c]=np.sqrt(1) #規則正しい\n",
        "  df.loc[df[c]=='1 - 2 times per week',c] = np.sqrt(2)\n",
        "  df.loc[df[c]=='3 - 4 times per week',c] = np.sqrt(4)\n",
        "  df[c] = df[c].astype(np.float16)\n",
        "                         \n",
        "  c = 'Exercise'\n",
        "  df.loc[df[c]=='I don\\'t typically exercise',c] = 0\n",
        "  df.loc[df[c]=='Daily or almost every day',c]=1 #規則正しい\n",
        "  df.loc[df[c]=='1 - 2 times per week',c] = 2\n",
        "  df.loc[df[c]=='3 - 4 times per week',c] = 4\n",
        "  df[c] = df[c].astype(np.float16)\n",
        "\n",
        "  c = 'TimeFullyProductive'\n",
        "  df.loc[df[c]=='Less than a month',c] = np.sqrt(0.5)\n",
        "  df.loc[df[c]=='One to three months',c] = np.sqrt(1)\n",
        "  df.loc[df[c]=='Three to six months',c] = np.sqrt(3)\n",
        "  df.loc[df[c]=='Six to nine months',c] = np.sqrt(6)\n",
        "  df.loc[df[c]=='Nine months to a year',c] = np.sqrt(9)\n",
        "  df.loc[df[c]=='More than a year',c]= np.sqrt(12)\n",
        "  df[c] = df[c].astype(np.float32)\n",
        "  c = 'AssessJob'\n",
        "  for i in range(1,11):\n",
        "    df[c+str(i)].fillna(-999,inplace=True)\n",
        "    df[c+str(i)] = df[c+str(i)].astype(np.int16)\n",
        "  c ='AssessBenefits'\n",
        "  for i in range(1,12):\n",
        "    df[c+str(i)].fillna(-999,inplace=True)\n",
        "    df[c+str(i)] = df[c+str(i)].astype(np.int16)\n",
        "  c='JobContactPriorities'\n",
        "  for i in range(1,6):\n",
        "    df[c+str(i)].fillna(-999,inplace=True)\n",
        "    df[c+str(i)] = df[c+str(i)].astype(np.int16)\n",
        "  c='AdsPriorities'\n",
        "  for i in range(1,8):\n",
        "    df[c+str(i)].fillna(-999,inplace=True)\n",
        "    df[c+str(i)] = df[c+str(i)].astype(np.int16)\n",
        "  c='JobEmailPriorities'\n",
        "  for i in range(1,3):\n",
        "    df[c+str(i)].fillna(-999,inplace=True)\n",
        "    df[c+str(i)] = df[c+str(i)].astype(np.int16)\n",
        "  print(\"feature_encoder end\")\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHeojojghmHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_add(tr,ts):\n",
        "  print(\"feature_add start\",tr.shape,ts.shape)\n",
        "  \n",
        "  tmp = pd.concat([tr.loc[~tr['YearsCodingProf'].isnull()],ts[~ts['YearsCodingProf'].isnull()]])[['Country','YearsCodingProf']].groupby('Country').mean().reset_index()\n",
        "  tmp.rename(columns={'YearsCodingProf':'Country_YearsCodingProf_Mean'},inplace=True)\n",
        "  tr = tr.merge(tmp,on=['Country'],how='left')\n",
        "  ts = ts.merge(tmp,on=['Country'],how='left')\n",
        "\n",
        "  tmp = pd.concat([tr.loc[~tr['Age'].isnull()],ts[~ts['Age'].isnull()]])[['Country','Age']].groupby('Country').mean().reset_index()\n",
        "  tmp.rename(columns={'Age':'Country_Age_Mean'},inplace=True)\n",
        "  tr = tr.merge(tmp,on=['Country'],how='left')\n",
        "  ts = ts.merge(tmp,on=['Country'],how='left')\n",
        "\n",
        "  tmp = pd.concat([tr.loc[~tr['Age'].isnull()],ts[~ts['Age'].isnull()]])[['Country','Age']].groupby('Country').std().reset_index()\n",
        "  tmp.rename(columns={'Age':'Country_Age_Std'},inplace=True)\n",
        "  tr = tr.merge(tmp,on=['Country'],how='left')\n",
        "  ts = ts.merge(tmp,on=['Country'],how='left')\n",
        "\n",
        "  tmp = pd.concat([tr.loc[(~tr['Age'].isnull()) & (~tr['Student'].isnull())],ts[(~ts['Age'].isnull()) & (~ts['Student'].isnull()) ]])[['Country','Student','Age']].groupby(['Country','Student']).mean().reset_index()\n",
        "  tmp.rename(columns={'Age':'Country_Student_Age_Mean'},inplace=True)\n",
        "  tr = tr.merge(tmp,on=['Country','Student'],how='left')\n",
        "  ts = ts.merge(tmp,on=['Country','Student'],how='left')\n",
        "  \n",
        "  tmp = pd.concat([tr.loc[(~tr['HoursComputer'].isnull())],ts[(~ts['HoursComputer'].isnull())]])[['Age','HoursComputer']].groupby(['Age']).mean().reset_index()\n",
        "  tmp.rename(columns={'HoursComputer':'Age_HoursComputer_Mean'},inplace=True)\n",
        "  tr = tr.merge(tmp,on=['Age'],how='left')\n",
        "  ts = ts.merge(tmp,on=['Age'],how='left')\n",
        "\n",
        "  tmp = pd.concat([tr.loc[(~tr['HoursOutside'].isnull())],ts[(~ts['HoursOutside'].isnull())]])[['Age','HoursOutside']].groupby(['Age']).mean().reset_index()\n",
        "  tmp.rename(columns={'HoursOutside':'Age_HoursOutside_Mean'},inplace=True)\n",
        "  tr = tr.merge(tmp,on=['Age'],how='left')\n",
        "  ts = ts.merge(tmp,on=['Age'],how='left')\n",
        "\n",
        "  tmp = pd.concat([tr,ts])[['Country','Hobby']].groupby('Country').count().reset_index()\n",
        "  tmp.rename(columns={'Hobby':'Country_Count'},inplace=True)\n",
        "  tmp['Country_Count'] = tmp['Country_Count'].astype(np.int32)\n",
        "  tr = tr.merge(tmp,on='Country',how='left')\n",
        "  ts = ts.merge(tmp,on='Country',how='left')\n",
        "\n",
        "  for c in ['Country','CompanySize','Age','LastNewJob','NumberMonitors','JobSatisfaction']:\n",
        "    tmp = tr[[c,TARGET]].groupby(c).mean().reset_index()\n",
        "    tmp.rename(columns={TARGET:c+'_Salary_Mean'},inplace=True)\n",
        "    tr = tr.merge(tmp,on=c,how='left')\n",
        "    ts = ts.merge(tmp,on=c,how='left')\n",
        "  \n",
        "  tmp = tr[['Employment','SalaryType',TARGET]].groupby(['Employment','SalaryType']).mean().reset_index()\n",
        "  tmp.rename(columns={TARGET:'Employment_SalaryType_Salary_Mean'},inplace=True)\n",
        "  tr = tr.merge(tmp,on=['Employment','SalaryType'],how='left')\n",
        "  ts = ts.merge(tmp,on=['Employment','SalaryType'],how='left')\n",
        "  print(\"feature_add end\",tr.shape,ts.shape)\n",
        "  return tr,ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "701tR1o-9-2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_features(tr,ts):\n",
        "  print(\"remove_features start\",tr.shape,ts.shape)\n",
        "  #データクリーニング\n",
        "  tr = tr.loc[~(tr['FrameworkWorkedWithCount'] >10)]\n",
        "  tr = tr.loc[~((tr['Age']==18) & (tr['HopeFiveYears']=='Retirement'))]\n",
        "  tr = tr.loc[tr['LanguageWorkedWithCount']<38]\n",
        "\n",
        "  remove_col = ['Currency','SexualOrientationCount','PlatformWorkedWithCount','PlatformDesireNextYearCount','SelfTaughtTypesCount','IDECount','LanguageDesireNextYearCount','DatabaseDesireNextYearCount','SurveyTooLong']#,'Country_Count'\n",
        "  remove_col += ['FrameworkWorkedWithCount','FrameworkDesireNextYearCount','RaceEthnicityCount','DatabaseWorkedWithCount','MethodologyCount','CommunicationToolsCount','ErgonomicDevicesCount',]#,'nanCnt','HackathonReasonsCount'\n",
        "  remove_col += ['EducationParents','StackOverflowDevStory','StackOverflowJobsRecommend','CommunicationTools_Facebook','SelfTaughtTypes_A college/university computer science or software engineering book']#'EducationTypes_Taken an online course in programming or software development e.g. a MOOC'\n",
        "  remove_col += ['SelfTaughtTypes_Internal Wikisp chat roomsp or documentation set up by my company for employees']\n",
        "  remove_col += ['HackathonReasons_To improve my ability to work on a team with other programmers','EducationTypes_Participated in a full-time developer training program or bootcamp','IDE_Zend']\n",
        "  remove_col += ['AdsActions_Saw an online advertisement and then researched it without clicking on the ad','VersionControlCount','VersionControl_Mercurial','IDE_Light Table']\n",
        "  for c in ['JobEmailPriorities']:\n",
        "    for i in range(3,8):\n",
        "      remove_col.append(c+str(i))\n",
        "  for c in ['AdsPriorities']:\n",
        "    for i in range(1,5):\n",
        "      remove_col.append(c+str(i))\n",
        "  for c in remove_col:\n",
        "    del tr[c],ts[c]\n",
        "\n",
        "  print(\"remove_features end\",tr.shape,ts.shape)\n",
        "  return tr,ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Umjgj11IdRRv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_split_column(col,df):\n",
        "  cols =[]\n",
        "  for c in df.columns:\n",
        "    if col in c:\n",
        "      cols.append(c)\n",
        "  return cols\n",
        "\n",
        "def column_compaction(df,col_prefix):\n",
        "  print(col_prefix+'_column_compaction start',df.shape)\n",
        "  p = col_prefix+\"WorkedWith_\"\n",
        "  for c in get_split_column(p,df):\n",
        "    nc  = c.replace(p,\"\")\n",
        "    df[nc] = df[c].astype(np.int8)\n",
        "    del df[c]\n",
        "\n",
        "  p = col_prefix+\"DesireNextYear_\"\n",
        "  for c in get_split_column(p,df):\n",
        "    nc  = c.replace(p,\"\")\n",
        "    df[nc] += df[c].astype(np.int8)\n",
        "    del df[c]\n",
        "  print(col_prefix+'_column_compaction end',df.shape)\n",
        "  return df\n",
        "\n",
        "def interaction_feature(df,features,newcolumn=\"\"):\n",
        "  if len(newcolumn) > 0 :\n",
        "    df[newcolumn] = \"\"\n",
        "\n",
        "  df[features[0]] = df[features[0]].astype(str)\n",
        "  for i in range(1,len(features)):\n",
        "    df[features[0]] += df[features[i]].astype(str)\n",
        "    del df[features[i]]\n",
        "\n",
        "  if len(newcolumn) > 0 :\n",
        "    df[newcolumn] = df[features[0]] \n",
        "    del df[features[0]]\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "531db9BdApTv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_interaction(df):\n",
        "  df.loc[df['Country']=='United States','Country'] = df['Country'].astype(str) + df['MilitaryUS'].astype(str)\n",
        "  del df['MilitaryUS']\n",
        "  df = interaction_feature(df,['DevType_Data scientist or machine learning specialist','EducationTypes_Taken an online course in programming or software development e.g. a MOOC'])#TRY\n",
        "  df = interaction_feature(df,['CheckInCode','Hobby'])\n",
        "  df = interaction_feature(df,['Student','DevType_Student'])\n",
        "  df = interaction_feature(df,['Python','IDE_IPython / Jupyter','IDE_PyCharm'])\n",
        "  df = interaction_feature(df,['Java','IDE_Eclipse','IDE_NetBeans'])\n",
        "  df = interaction_feature(df,['Ruby','IDE_RubyMine'])\n",
        "  df = interaction_feature(df,['R','IDE_RStudio'])\n",
        "  df = interaction_feature(df,['FormalEducation','UndergradMajor'])\n",
        "  df = interaction_feature(df,['EducationTypes_Participated in a hackathon','HackathonReasonsCount'])\n",
        "  df = interaction_feature(df,['MongoDB','Heroku'])\n",
        "  df = interaction_feature(df,['Drupal','WordPress'],'Drupal_WordPress')\n",
        "  df = interaction_feature(df,['Google Home','Amazon Echo'],'SmartDevice')\n",
        "  df = interaction_feature(df,['EducationTypes_Taken a part-time in-person course in programming or software development','SelfTaughtTypes_Pre-scheduled tutoring or mentoring sessions with a friend or colleague'])\n",
        "  df = interaction_feature(df,['EducationTypes_Participated in online coding competitions e.g. HackerRankp CodeChefp TopCoder','HackathonReasons_To help me find new job opportunities'])\n",
        "  df = interaction_feature(df,['DevType_Engineering manager','DevType_Product manager','DevType_C-suite executive CEOp CTOp etc.'],'DevType_Manager')\n",
        "  df = interaction_feature(df,['DevType_Data or business analyst','DevType_Data scientist or machine learning specialist','DevType_Marketing or sales professional'],'DevType_DataScientist')\n",
        "  df = interaction_feature(df,['DevType_Designer','DevType_Game or graphics developer','DevType_Front-end developer'],'DevType_Designer')\n",
        "  df = interaction_feature(df,['DevType_Database administrator','DevType_System administrator'],'DevType_Admin')\n",
        "  df = interaction_feature(df,['DevType_Desktop or enterprise applications developer','DevType_Embedded applications or devices developer','DevType_Mobile developer'],'DevType_Developer')\n",
        "  df = interaction_feature(df,['DevType_QA or test developer','DevType_Back-end developer','DevType_DevOps specialist'],'DevType_Infra')\n",
        "  df = interaction_feature(df,['DevType_Full-stack developer','DevType_Educator or academic researcher'],'DevType_Other')\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT6T-HqyO91v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_weight(data):\n",
        "  data['weight'] = 1\n",
        "  data.loc[data['nanCnt'].astype(np.float)>=100,'weight'] = 0.8\n",
        "  del data['nanCnt']\n",
        "  return data\n",
        "\n",
        "def columns_sort(tr,ts):\n",
        "  tr['data'] = 'train'\n",
        "  ts['data'] ='test'\n",
        "\n",
        "  data = pd.concat([tr,ts])\n",
        "  tr = data.loc[data['data']=='train'].drop('data',axis=1)\n",
        "  ts = data.loc[data['data']=='test'].drop('data',axis=1)\n",
        "  del data\n",
        "  return tr,ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fae-OncE8RFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(tr,ts):\n",
        "  for df in [tr,ts]:\n",
        "    df = add_nan_count_and_clean(df)\n",
        "    df = preprocess_feature_split(df)\n",
        "    df = feature_encoder(df)\n",
        "\n",
        "  tr,ts = feature_add(tr,ts)\n",
        "\n",
        "  tr = preprocess_other(tr)\n",
        "  ts = preprocess_other(ts)\n",
        "\n",
        "  tr,ts = remove_features(tr,ts)\n",
        "\n",
        "  for c in ['Database','Framework','Platform','Language']:\n",
        "    tr = column_compaction(tr,c)\n",
        "    ts = column_compaction(ts,c)\n",
        "  \n",
        "  tr =  preprocess_interaction(tr)\n",
        "  ts =  preprocess_interaction(ts)\n",
        "  \n",
        "  tr = set_weight(tr)\n",
        "  ts = set_weight(ts)\n",
        "\n",
        "  tr,ts = columns_sort(tr,ts)\n",
        "  tr.to_csv(\"preprocess_\"+TRAIN_FILE)\n",
        "  ts.to_csv(\"preprocess_\"+TEST_FILE)\n",
        "  return tr,ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMRkt_ndHy2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def train():\n",
        "  #パラメータチューニング時のみバリデーションデータ作成。提出ファイル作成時は訓練データをすべて訓練に使用。\n",
        "  #CatBoostがRAMの都合上、lr高めiteration低め\n",
        "  cat_params = {\n",
        "      'learning_rate': 0.05,\n",
        "      'eval_metric': 'RMSE',\n",
        "      'random_seed': 1205,\n",
        "      'use_best_model': False,\n",
        "      'verbose': 500,\n",
        "      'num_boost_round':7000,\n",
        "      'od_type': 'Iter',\n",
        "      'od_wait': 300,\n",
        "      'one_hot_max_size':3}\n",
        "      \n",
        "  lgb_params = {\n",
        "        'task' : 'train',\n",
        "        'boosting_type' : 'dart',\n",
        "        'objective' : 'regression',\n",
        "        'metric' : 'rmse',\n",
        "        'num_leaves' : 50,\n",
        "        'learning_rate' : 0.01,\n",
        "        'feature_fraction' : 0.8,\n",
        "        'bagging_fraction' : 0.8,\n",
        "        'bagging_freq': 5}\n",
        "  #lgb 3モデル catboost 3モデル作成\n",
        "  for d in [\"\",\"Country\",\"Country_Count\"]:\n",
        "    train_data = pd.read_csv(\"preprocess_\"+TRAIN_FILE,index_col=0)\n",
        "    test_data = pd.read_csv(\"preprocess_\"+TEST_FILE,index_col=0)\n",
        "\n",
        "    if d in train_data.columns:\n",
        "      del train_data[d],test_data[d]\n",
        "    \n",
        "    categorical_features_indices = []\n",
        "    df = train_data.drop(TARGET, axis=1)\n",
        "    for c in range(0,len(df.columns)):\n",
        "      if 'float' not in str(df[df.columns[c]].dtype):\n",
        "        categorical_features_indices.append(df.columns[c])\n",
        "        train_data[df.columns[c]].fillna(-999,inplace=True)\n",
        "        test_data[df.columns[c]].fillna(-999,inplace=True)\n",
        "        train_data[df.columns[c]] =  train_data[df.columns[c]].astype('category')\n",
        "        test_data[df.columns[c]] =  test_data[df.columns[c]].astype('category')\n",
        "    \n",
        "    model = CatBoostRegressor(**cat_params)\n",
        "    cat_train = Pool(train_data.drop(TARGET,axis=1).drop('weight',axis=1), train_data[TARGET], cat_features=categorical_features_indices)\n",
        "    model.fit(cat_train)\n",
        "    model.save_model('cat_' + d)\n",
        "    del model\n",
        "    \n",
        "    lgb_train = lgb.Dataset(train_data.drop(TARGET,axis=1).drop('weight',axis=1), train_data[TARGET],weight = train_data['weight'])\n",
        "    lgb_train.free_raw_data = None\n",
        "    model = lgb.train(lgb_params,\n",
        "            lgb_train,\n",
        "            num_boost_round=27000,\n",
        "            categorical_feature = categorical_features_indices)\n",
        "  \n",
        "    model.save_model('lgb_' + d)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90n6k9AUIegs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "d28b8f3a-ee57-4d1a-da6e-e5a22d1c91d1"
      },
      "source": [
        "train_data,test_data = preprocess(train_data,test_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "add_nan_count start (33857, 127)\n",
            "add_nan_count end (33857, 124)\n",
            "preprocess_feature_split start (33857, 124)\n",
            "preprocess_feature_split end (33857, 444)\n",
            "feature_encoder start\n",
            "feature_encoder end\n",
            "add_nan_count start (11259, 127)\n",
            "add_nan_count end (11259, 124)\n",
            "preprocess_feature_split start (11259, 124)\n",
            "preprocess_feature_split end (11259, 444)\n",
            "feature_encoder start\n",
            "feature_encoder end\n",
            "feature_add start (33857, 444) (11259, 444)\n",
            "feature_add end (33857, 458) (11259, 458)\n",
            "preprocess start (33857, 458)\n",
            "preprocess end (33856, 458)\n",
            "preprocess start (11259, 458)\n",
            "preprocess end (11259, 458)\n",
            "remove_features start (33856, 458) (11259, 458)\n",
            "remove_features end (33851, 420) (11259, 420)\n",
            "Database_column_compaction start (33851, 420)\n",
            "Database_column_compaction end (33851, 399)\n",
            "Database_column_compaction start (11259, 420)\n",
            "Database_column_compaction end (11259, 399)\n",
            "Framework_column_compaction start (33851, 399)\n",
            "Framework_column_compaction end (33851, 387)\n",
            "Framework_column_compaction start (11259, 399)\n",
            "Framework_column_compaction end (11259, 387)\n",
            "Platform_column_compaction start (33851, 387)\n",
            "Platform_column_compaction end (33851, 360)\n",
            "Platform_column_compaction start (11259, 387)\n",
            "Platform_column_compaction end (11259, 360)\n",
            "Language_column_compaction start (33851, 360)\n",
            "Language_column_compaction end (33851, 322)\n",
            "Language_column_compaction start (11259, 360)\n",
            "Language_column_compaction end (11259, 322)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DocMUxXC2dS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "1345ddca-bf5c-47b9-ee05-47d528ceca9b"
      },
      "source": [
        "train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:\tlearn: 42865.4670333\ttotal: 335ms\tremaining: 5m 35s\n",
            "500:\tlearn: 19380.7599703\ttotal: 2m 23s\tremaining: 2m 22s\n",
            "999:\tlearn: 18359.4244421\ttotal: 4m 45s\tremaining: 0us\n",
            "0:\tlearn: 42864.3273149\ttotal: 264ms\tremaining: 4m 24s\n",
            "500:\tlearn: 19380.9679693\ttotal: 2m 18s\tremaining: 2m 17s\n",
            "999:\tlearn: 18420.2282819\ttotal: 4m 36s\tremaining: 0us\n",
            "0:\tlearn: 42851.8414758\ttotal: 256ms\tremaining: 4m 15s\n",
            "500:\tlearn: 19428.7606750\ttotal: 2m 14s\tremaining: 2m 14s\n",
            "999:\tlearn: 18462.6561801\ttotal: 4m 30s\tremaining: 0us\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nydHEQCSaeK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def predict():\n",
        "  cols = [\"\",\"Country\",\"Country_Count\"]#\n",
        "  emsamble = pd.read_csv(SUB_FILE)\n",
        "  emsamble = emsamble.set_index('No')\n",
        "  for d in cols:\n",
        "    test_data = pd.read_csv(\"preprocess_\"+TEST_FILE,index_col=0)\n",
        "    if d in train_data.columns:\n",
        "      del test_data[d]\n",
        "\n",
        "    categorical_features_indices = []\n",
        "    df = test_data.drop(TARGET, axis=1)\n",
        "    for c in range(0,len(df.columns)):\n",
        "      if 'float' not in str(df[df.columns[c]].dtype):\n",
        "        categorical_features_indices.append(df.columns[c])\n",
        "        test_data[df.columns[c]].fillna(-999,inplace=True)\n",
        "        test_data[df.columns[c]] =  test_data[df.columns[c]].astype('category')\n",
        "    \n",
        "    model = CatBoostRegressor()\n",
        "    model.load_model('cat_'+d)\n",
        "    predictions = model.predict(test_data.drop(TARGET,axis=1).drop('weight',axis=1))\n",
        "    print(len(predictions[predictions<0]))\n",
        "    predictions[predictions<5000] = 5000\n",
        "\n",
        "    submit = pd.read_csv(SUB_FILE)\n",
        "    submit[TARGET] = predictions\n",
        "    submit = submit.set_index('No')\n",
        "    emsamble +=submit * (0.4/3)\n",
        "    model = lgb.Booster(model_file='lgb_' + d)\n",
        "    predictions = model.predict(test_data.drop(TARGET,axis=1).drop('weight',axis=1))\n",
        "    print(len(predictions[predictions<0]))\n",
        "    predictions[predictions<0] = 0\n",
        "\n",
        "    submit = pd.read_csv(SUB_FILE)\n",
        "    submit[TARGET] = predictions\n",
        "    submit = submit.set_index('No')\n",
        "    emsamble +=submit * (0.6/3)\n",
        "    submit.to_csv('LGBM'+d+'.csv')\n",
        "  \n",
        "  emsamble.to_csv('Quevico_Submission.csv')\n",
        "predict()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
